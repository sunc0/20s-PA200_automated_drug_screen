{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZGESbi46nWA",
        "outputId": "ccb836f5-9be6-4523-b572-3b2df22a844e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘plyr’, ‘Rcpp’\n",
            "\n",
            "\n",
            "\n",
            "Attaching package: ‘tidyr’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:reshape2’:\n",
            "\n",
            "    smiths\n",
            "\n",
            "\n",
            "\n",
            "Attaching package: ‘dplyr’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    filter, lag\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    intersect, setdiff, setequal, union\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"reshape2\")\n",
        "library(reshape2)\n",
        "library(tidyr)\n",
        "library(dplyr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#open the r notebook on colab\n",
        "#load a formated file with two columns, first one is well number, second is the slope value, give it header where the second column name is the name of the dataset\n",
        "#make a folder called DATA\n",
        "dir.create(\"/DATA\")\n",
        "# set the file paths for the original and new directories\n",
        "data_dir <- \"/DATA/\""
      ],
      "metadata": {
        "id": "evjaljbFsWNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8199b1cd-9e2b-43df-a51c-251cd81e567b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message in dir.create(\"/DATA\"):\n",
            "“'/DATA' already exists”\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7fFruS9u7UHL"
      },
      "outputs": [],
      "source": [
        "data_dir <- \"/DATA/\"\n",
        "# Get a list of all the files in the directory\n",
        "file_list <- list.files(path = data_dir)\n",
        "# Loop through the file list and read in only the TSV files\n",
        "for (file_name in file_list) {\n",
        "  if (endsWith(file_name, \".tsv\")) {  # Check if the file ends with \".tsv\"\n",
        "\n",
        "data <- read.table(paste0(data_dir, file_name), header = TRUE, stringsAsFactors = FALSE, sep = \"\\t\")\n",
        "\n",
        "head(data)\n",
        "\n",
        "#retrieve the NAME OF THE FILE INSTEAD OF THE header for later (to name the output files)\n",
        "#col_header <- names(data)[2]\n",
        "col_header <- file_name\n",
        "# Rename the columns\n",
        "colnames(data) <- c(\"position\", \"intensity\")\n",
        "\n",
        "# Split the position column into two columns\n",
        "data <- separate(data, position, c(\"letter\", \"number\"), sep = 1)\n",
        "\n",
        "# Convert the number column to numeric\n",
        "data$number <- as.numeric(data$number)\n",
        "\n",
        "# Reshape the data into the desired format\n",
        "data <- spread(data, letter, intensity)\n",
        "\n",
        "# Set the row names to the number column\n",
        "row.names(data) <- data$number\n",
        "\n",
        "# Remove the number column\n",
        "data <- select(data, -number)\n",
        "\n",
        "# transpose the dataframe\n",
        "data <- t(data)\n",
        "\n",
        "# View the resulting data frame\n",
        "View(data)\n",
        "\n",
        "#every dataset was laid out by column and row, the way it looked like on an actual, physical plate, then the slope values were normalized first by substracting the column median for each value of the rexpective column, and then by substracting the row median for each value of the respective row.\n",
        "#The first two columns were not used in the basic normalization procedure, as they are a separate Gaussian-distributed population. They were thus normalized separately.\n",
        "\n",
        "data_wo_first_col <- data[, 3:ncol(data)]\n",
        "\n",
        "# calculate median of each column using apply function\n",
        "col_medians <- apply(data_wo_first_col, 2, median)\n",
        "# subtract column median from all elements\n",
        "df_col_centered <- sweep(data_wo_first_col, 2, col_medians, \"-\")\n",
        "# calculate median of each row using apply function\n",
        "row_medians <- apply(df_col_centered, 1, median)\n",
        "# subtract row median from all elements\n",
        "df_col_and_row_centered <- sweep(df_col_centered, 1, row_medians, \"-\")\n",
        "\n",
        "sd(as.matrix(data_wo_first_col))\n",
        "sd(as.matrix(df_col_and_row_centered))\n",
        "\n",
        "# standardize the data frame - The resulting dataframe was standardized, meaning every value was recalculated as a distance fromp the mean, using \"sd\" function in R.\n",
        "sd_after_centering <- sd(as.matrix(df_col_and_row_centered))\n",
        "\n",
        "# The distance between the Guassian of the first two columns in the raw dataset versus the Gaussian of the rest of the columns dataset was then calculated and this distance was subtracted from the raw values of the first two columns. This tranformed two columns were now joined with the rest of the standardized dataset into a whole.\n",
        "mean_of_col_medians <- mean(col_medians)\n",
        "merged_df <- cbind(data[, 1:2] - mean_of_col_medians, df_col_and_row_centered)\n",
        "df_standardized <- merged_df / sd_after_centering\n",
        "\n",
        "ncol(data)\n",
        "ncol(data_wo_first_col)\n",
        "ncol(df_col_and_row_centered)\n",
        "ncol(df_standardized)\n",
        "\n",
        "# convert the standard table to long format\n",
        "my_table_long <- melt(df_standardized, varnames = c(\"row\", \"col\"))\n",
        "\n",
        "# create a new data frame with row and column coordinates and values\n",
        "my_new_table <- data.frame(\n",
        "  coordinates = paste(my_table_long$row, my_table_long$col, sep = \"\"),\n",
        "  values = my_table_long$value\n",
        ")\n",
        "write.table(my_new_table, paste0(\"/DATA/\",col_header,\"_median-corrected_long_table1.tsv\"), sep=\"\\t\", quote=FALSE,)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "hist(as.matrix(data), nclass = 75, main=\"before normalization\")\n",
        "hist(as.matrix(df_col_and_row_centered), nclass = 75, main=\"after normalization\")\n",
        "hist(as.matrix(df_standardized), nclass = 75, main=\"after standardization\")\n",
        "\n",
        "# Plot the density\n",
        "plot(density(as.matrix(df_standardized) + median(as.matrix(data))),\n",
        "  main=\"Data distribution before and after normalization\",\n",
        "  col = \"green\",\n",
        "  ylim = c(0,3)\n",
        ")\n",
        "\n",
        "lines(density(as.matrix(df_col_and_row_centered) + median(as.matrix(data))), col = \"blue\")\n",
        "lines(density(as.matrix(data)), col = \"red\")\n",
        "\n",
        "# Add a legend\n",
        "legend(\"topleft\", legend = c(\"before normalization\", \"after normalization\",\"after standardization\"), col = c(\"red\", \"blue\",\"green\"), lty = 1)\n",
        "\n",
        "#here we are writing the normalized dataset into a table in a tsv format\n",
        "write.table(df_standardized, paste0(\"/DATA/\",col_header,\"_median-corrected_table1.tsv\"), sep=\"\\t\", quote=FALSE,)\n",
        "\n",
        "# Open a PDF device\n",
        "pdf(paste0(\"/DATA/\",col_header,\"histogram_plots.pdf\"))\n",
        "\n",
        "\n",
        "hist(as.matrix(data), nclass = 75, main=\"before normalization\")\n",
        "hist(as.matrix(df_col_and_row_centered), nclass = 75, main=\"after normalization\")\n",
        "hist(as.matrix(df_standardized), nclass = 75, main=\"after standardization\")\n",
        "\n",
        "# Plot the density\n",
        "plot(density(as.matrix(df_standardized) + median(as.matrix(data))),\n",
        "  main=\"Data distribution before and after normalization\",\n",
        "  col = \"green\",\n",
        "  ylim = c(0,3)\n",
        ")\n",
        "\n",
        "lines(density(as.matrix(df_col_and_row_centered) + median(as.matrix(data))), col = \"blue\")\n",
        "lines(density(as.matrix(data)), col = \"red\")\n",
        "\n",
        "# Add a legend\n",
        "legend(\"topleft\", legend = c(\"before normalization\", \"after normalization\",\"after standardization\"), col = c(\"red\", \"blue\",\"green\"), lty = 1)\n",
        "# Close the PDF device\n",
        "dev.off()\n",
        "\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge long table files"
      ],
      "metadata": {
        "id": "T-4FNuzFyv14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the working directory to the folder containing the .tsv files\n",
        "setwd(data_dir)\n",
        "# List all .tsv files in the folder that contain \"long\" in the file name\n",
        "long_table_files <- list.files(pattern = \"long.*\\\\.tsv$\")\n",
        "\n",
        "# Create an empty data frame to store the merged data\n",
        "long_table_merged <- data.frame()\n",
        "\n",
        "# Loop over each file and merge it into the merged data frame\n",
        "for (file in long_table_files) {\n",
        "  # Read the data from the file\n",
        "  long_table_data <- read.table(file, header = TRUE, sep = \"\\t\")\n",
        "\n",
        "  # Add a column to the data with the name of the file\n",
        "  long_table_data$filename <- basename(file)\n",
        "\n",
        "  # Merge the data into the merged data frame\n",
        "  long_table_merged <- rbind(long_table_merged, long_table_data)\n",
        "}\n",
        "long_table_merged <- data.frame(lapply(long_table_merged, function(x) gsub(\"_median-corrected_long_table1.tsv\", \"\", x)))\n",
        "# Write the merged data frame to a file called \"long_merged.tsv\"\n",
        "write.table(long_table_merged, file = \"long_tables_merged.tsv\", sep = \"\\t\", row.names = FALSE)\n"
      ],
      "metadata": {
        "id": "-OeoOxI_vWem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlink(\"/DATA/\", recursive=TRUE)"
      ],
      "metadata": {
        "id": "fGXy8hYuzeRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT7RVu16DzZ6"
      },
      "outputs": [],
      "source": [
        "# Open a PDF device\n",
        "pdf(\"/DATA/box_plots_and_pvals.pdf\")\n",
        "# one boxplot for the whole dataset before and after normalization\n",
        "boxplot(as.vector(as.matrix(data)))\n",
        "boxplot(as.vector(as.matrix(df_standardized)))\n",
        "#use z-score on the y axis instead for the boxplot\n",
        "all_values_as_vec <- as.vector(as.matrix(df_standardized))\n",
        "z_scores <- scale(all_values_as_vec)\n",
        "boxplot(z_scores)\n",
        "\n",
        "#one boxplot for each column for the whole dataset before and after normalization\n",
        "boxplot((as.matrix(data)))\n",
        "boxplot((as.matrix(df_standardized)))\n",
        "\n",
        "\n",
        "# Compute the p-values of the z-scores\n",
        "p_values <- 2 * (1 - pnorm(abs(z_scores)))\n",
        "final_df <- data.frame(values = all_values_as_vec, z_scores = scale(all_values_as_vec), p_values = p_values)\n",
        "sorted_df <- final_df %>%\n",
        "  arrange(p_values)\n",
        "  View(sorted_df)\n",
        "  df_standardized_mat <- as.matrix(df_standardized)\n",
        "mean_x <- mean(df_standardized_mat)\n",
        "sd_x <- sd(df_standardized_mat)\n",
        "z_scored_matrix <- (df_standardized_mat - mean_x) / sd_x\n",
        "\n",
        "#z_scored_matrix <- scale(as.matrix(df_standardized))\n",
        "\n",
        "pvalues_matrix <- 2 * (1 - pnorm(abs(z_scored_matrix)))\n",
        "#pvalues_vec <- 2 * (1 - pnorm(abs(as.vector(z_scored_matrix))))\n",
        "#pvalues_matrix <- matrix(p_values, nrow = nrow(df_standardized_mat), ncol = ncol(df_standardized_mat))\n",
        "\n",
        "# set the cutoff\n",
        "zscore_cutoff <- -3\n",
        "pvalue_cutoff <- 0.01\n",
        "\n",
        "# print the values\n",
        "# Create a data frame containing the indices and z-scores\n",
        "#indices <- which(z_scored_matrix < zscore_cutoff, arr.ind = TRUE)\n",
        "indices <- which(pvalues_matrix < pvalue_cutoff, arr.ind = TRUE)\n",
        "\n",
        "#here we are making a shortlist of the best hits over the indicated threshold\n",
        "df <- data.frame(\n",
        "  col_index = colnames(df_standardized)[indices[,2]],\n",
        "  row_index = rownames(df_standardized)[indices[,1]],\n",
        "  initial_values = data[indices],\n",
        "  normalized_values = df_standardized[indices],\n",
        "  zscores = z_scored_matrix[indices],\n",
        "  p_values = pvalues_matrix[indices]\n",
        ")\n",
        "\n",
        "sorted_df2 <- df %>%\n",
        "  arrange(p_values)\n",
        "\n",
        "View(sorted_df2)\n",
        "# Close the PDF device\n",
        "dev.off()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}